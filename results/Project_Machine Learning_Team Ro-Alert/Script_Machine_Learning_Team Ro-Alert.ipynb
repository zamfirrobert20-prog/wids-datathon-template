{"cells":[{"cell_type":"markdown","metadata":{"id":"2-cv9hwnYWbm"},"source":["# WiDS Datathon 2026 Notebook\n","This is where your analysis begins. Use this notebook for EDA, modeling, and explanations."]},{"cell_type":"markdown","source":["## Project Title & Team Info\n","\n","**Project Title**: _Workshop 1: WiDS University Datathon 2026_  \n","**Team Name**: _Team Alert_  \n","**University**: _Bucharest University of Economic Studies_  \n","**Course**: _Software Open Source for Statistics and Data Science_  \n","**Term**: _1st Semester, 2025_  \n","\n","**Team Members**:  \n","\n","- »öilicƒÉ Mihnea David (GitHub: [@David-Mihnea](https://github.com/David-Mihnea))\n","- Zamfir Robert Dan (GitHub: [@zamfirrobert20-prog](https://github.com/zamfirrobert20-prog))\n","- Radu Alexandru Claudiu (GitHub: [@raduclaudiu20-art](https://github.com/raduclaudiu20-art))\n","- SƒÉndulescu Crina (GitHub: [@ccrinasandulescu](https://github.com/ccrinasandulescu))\n","- Sasu Sabrina (GitHub: [@sasusabrina22](https://github.com/sasusabrina22?tab=repositories))\n","- Sandu Bianca (GitHub: [@sandubianca](https://github.com/sandubianca))\n","\n"],"metadata":{"id":"lYnjTpW2AM-3"}},{"cell_type":"markdown","source":["### üîπ Route 1: Accelerating Equitable Evacuations\n","\n","**Core Question:**  \n","*How can we reduce delays in evacuation alerts and improve response times for the communities that are most at risk?*\n","\n","This route focuses on analyzing how and when evacuation alerts are triggered ‚Äî and how we can improve timeliness and fairness in communication, especially for vulnerable populations."],"metadata":{"id":"fqHjA8_iGowI"}},{"cell_type":"markdown","source":["## Dataset Overview\n","\n","Summarize the datasets you used and how you processed them.\n","\n","- `evac_zone_status_geo_event_map.csv`: maps wildfire events to evacuation zones\n","- `evac_zones_gis_evaczone.csv`: defines evacuation zones as spatial entities, including their identifiers, names, activity status\n","- `geo_events_geoevent.csv`: records of geographic events, including wildfire incidents, with their location\n","- `geo_events_geoeventchangelog.csv`: time-stamped updates to wildfire events, capturing changes in reported field\n"],"metadata":{"id":"VIcohSnlCOOp"}},{"cell_type":"markdown","source":["**Load Data**"],"metadata":{"id":"8LyFO61H3o0j"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFVv4of6Z5Hb"},"outputs":[],"source":["from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QKhjGEBEdsz"},"outputs":[],"source":["!unzip DataWids.zip -d data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqJcnxrwAnDS"},"outputs":[],"source":["#libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.style.use(\"seaborn-v0_8-whitegrid\")\n","sns.set_theme()\n","plt.colormaps()\n","\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ysmjs1vaAuUM"},"outputs":[],"source":["geo_events    = pd.read_csv(\"/content/data/DataWids/geo_events_geoevent.csv\", low_memory=True)\n","change_log   = pd.read_csv(\"/content/data/DataWids/geo_events_geoeventchangelog.csv\", low_memory=True)\n","evac_zones      = pd.read_csv(\"/content/data/DataWids/evac_zones_gis_evaczone.csv\", low_memory=True)\n","evac_map  = pd.read_csv(\"/content/data/DataWids/evac_zone_status_geo_event_map.csv\", low_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1HKDEB7BiQF"},"outputs":[],"source":["print(\"Loaded:\")\n","for name, df in zip([\"geo_events\",\"change_log\",\"evac_zones\",\"evac_map\"],\n","                    [geo_events,change_log,evac_zones,evac_map]):\n","    print(f\"  {name:10s} {df.shape}\")"]},{"cell_type":"markdown","source":["**Data Cleaning**"],"metadata":{"id":"MIy1pNqT4Agp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsZmQbRBGKnC"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","\n","def extract_json_field(js, key):\n","    if not isinstance(js, str) or \"{\" not in js:\n","        return None\n","    try:\n","        js = js.strip().strip('\"').strip(\"'\")\n","        parsed = json.loads(js)\n","        return parsed.get(key)\n","    except:\n","        return None\n","\n","def extract_change_value(js, key):\n","    parsed = extract_json_field(js, key)\n","    if isinstance(parsed, list) and len(parsed) >= 2:\n","        return parsed[1]\n","    return None\n","\n","# Extract 'geo_event_type' from the 'data' column first\n","geo_events['geo_event_type'] = geo_events['data'].apply(lambda x: extract_json_field(x, 'geo_event_type'))\n","\n","# Now filter based on the extracted 'geo_event_type'\n","geo_events = geo_events[geo_events[\"geo_event_type\"] == \"wildfire\"].copy()\n","\n","for col in [\"is_prescribed\", \"is_fps\", \"containment\", \"acreage\"]:\n","    geo_events[col] = geo_events[\"data\"].apply(lambda x: extract_json_field(x, col))\n","\n","fields_to_keep = [\"id\", \"geo_event_type\", \"date_created\", \"date_modified\", \"name\", \"notification_type\", \"lat\", \"lng\",\n","                  \"is_prescribed\", \"is_fps\", \"containment\", \"acreage\"]\n","geo_events = geo_events[fields_to_keep].copy()\n","\n","change_log['rate_of_spread'] = change_log['changes'].apply(lambda x: extract_change_value(x, 'radio_traffic_indicates_rate_of_spread'))\n","change_log['structure_threat'] = change_log['changes'].apply(lambda x: extract_change_value(x, 'radio_traffic_indicates_structure_threat'))\n","change_log['spotting'] = change_log['changes'].apply(lambda x: extract_change_value(x, 'radio_traffic_indicates_spotting'))\n","\n","change_log = change_log[[\"geo_event_id\", \"date_created\", \"rate_of_spread\", \"structure_threat\", \"spotting\"]].copy()\n","\n","print(\"After cleaning:\")\n","print(f\"  events    {geo_events.shape}\")\n","print(f\"  changes   {change_log.shape}\")\n","print(f\"  evac_zones {evac_zones.shape}\")\n","print(f\"  evac_map  {evac_map.shape}\")\n","\n","print(\"\\nExtracted fields preview:\")\n","print(geo_events[[\"id\", \"geo_event_type\", \"containment\", \"acreage\", \"is_fps\", \"is_prescribed\"]].head(10))\n","\n","print(\"\\nNon-null counts for extracted fields:\")\n","print(geo_events[[\"containment\", \"acreage\", \"is_fps\", \"is_prescribed\"]].notna().sum())"]},{"cell_type":"code","source":["def to_dt(df, cols):\n","    for c in cols:\n","        if c in df.columns:\n","            df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True)\n","    return df\n","\n","geo_events = to_dt(geo_events, [\"date_created\", \"date_modified\"])\n","change_log = to_dt(change_log, [\"date_created\"])"],"metadata":{"id":"gMKMDNH-Iafn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged = change_log.merge(\n","    geo_events,\n","    left_on=\"geo_event_id\",\n","    right_on=\"id\",\n","    how=\"inner\",\n","    suffixes=(\"_log\", \"_evt\")\n",")\n","\n","merged['alert_lag_min'] = (merged['date_created_log'] - merged['date_created_evt']).dt.total_seconds() / 60\n","\n","merged = merged.merge(\n","    evac_map[[\"geo_event_id\", \"uid_v2\"]].drop_duplicates(),\n","    left_on=\"id\",\n","    right_on=\"geo_event_id\",\n","    how=\"left\"\n",")\n","\n","merged = merged.merge(\n","    evac_zones.drop_duplicates(\"uid_v2\"),\n","    on=\"uid_v2\",\n","    how=\"left\",\n","    suffixes=(\"\", \"_evac\")\n",")\n","\n","print(\"Merged dataset:\", merged.shape)"],"metadata":{"id":"9-49RkFAJFOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["missing_values = pd.DataFrame({\n","    'Variable': merged.columns,\n","    'Missing values count': merged.isnull().sum().values,\n","    'Missing values %': (merged.isnull().sum().values / len(merged) * 100)})\n","\n","unique_values = pd.DataFrame({\n","    'Variable': merged.columns,\n","    'Unique values count': merged.nunique().values})\n","\n","feature_types = pd.DataFrame({\n","    'Variable': merged.columns,\n","    'Data type': merged.dtypes.astype(str)})\n","\n","summary_df = (missing_values\n","    .merge(unique_values, on='Variable', how='left')\n","    .merge(feature_types, on='Variable', how='left'))\n","\n","summary_df = summary_df.sort_values(by='Missing values %', ascending=False)\n","\n","summary_df.style.background_gradient(cmap='rocket_r').format({\n","    'Missing values %': '{:.2f}',\n","    'Unique values count': '{:,}',\n","    'Missing values count': '{:,}'})"],"metadata":{"id":"lkuWMovmKKnS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["High Missingness (> 90% missing)\n","\n","Variables: spotting (99.89%), structure_threat (99.59%), status (98.60%), rate_of_spread (97.04%).\n","\n","Interpretation: These fields represent specialized radio traffic reports and official evacuation orders. Their high sparsity is expected, as \"Extreme\" spread or \"Structure Threats\" occur only in high-severity escalations. For our Alert Engine, these are not predictors, but critical triggers (when present, they override standard priority).\n","\n","Moderate Missingness (10% - 60%)\n","\n","Variables: external_status (54.70%), display_name (44.78%), uid_v2 (27.57%), containment (11.96%), is_fps (11.86%).\n","\n","Interpretation: This missingness reflects the lifecycle of a wildfire. Many incidents are controlled quickly (indicated by is_fps) before they are assigned to specific evacuation zones or formal county-level naming.\n","\n","Low/No Missingness (0% - 3%)\n","\n","Variables: acreage (2.94%), date_created_log (0.00%), alert_lag_min (0.00%).\n","\n","Interpretation: These are our most reliable data points. acreage serves as the primary physical metric, while the complete timeline data (date_created) allows for a robust Alert Lag analysis, which is the core of our predictive modeling.\n","\n","Unique Values Insights\n","\n","Incident Scale: Over 42,000 unique id values confirm a vast dataset of distinct wildfire events.\n","\n","Priority Triggers: notification_type and is_prescribed show very low cardinality (2 unique values), making them ideal categorical filters for segregating planned burns from emergency wildfires."],"metadata":{"id":"rkezav2uLhva"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.datasets import make_blobs\n","%matplotlib inline"],"metadata":{"id":"2exJZeMSjh2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged.info()"],"metadata":{"id":"aPTdDKAUj278"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will not use 'pending_updates' as it contains only NaN values even though it's a numerical variable"],"metadata":{"id":"8aFdNq-e8C_c"}},{"cell_type":"markdown","source":["# **Clusterization**"],"metadata":{"id":"QpsTuEmg6p-R"}},{"cell_type":"code","source":["df = merged[[\"containment\", \"acreage\", \"alert_lag_min\"]].dropna()"],"metadata":{"id":"Mv0pohq6oc_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in df.columns:\n","    # Drop NaN values for the current column before plotting\n","    data_to_plot = df[col].dropna()\n","\n","    # Only plot if there are actual values remaining after dropping NaNs\n","    if not data_to_plot.empty:\n","        plt.figure(figsize=(4, 3))\n","        plt.hist(data_to_plot, bins=20)\n","        plt.title(f\"Histogram for variable: {col}\")\n","        plt.xlabel(col)\n","        plt.ylabel(\"Frequency\")\n","        plt.grid(True)\n","        plt.show()\n","    else:\n","        print(f\"Skipping histogram for '{col}' as it contains only NaN values.\")"],"metadata":{"id":"XpKvJwGXn22L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **Containment:** The distribution is extremely concentrated near 100%, indicating that most recorded wildfire events are reported as nearly fully contained, with relatively few observations at lower containment levels.\n","\n","* **Acreage:** The distribution is highly right-skewed, showing that the majority of fires affect relatively small areas, while a small number of extreme events account for very large burned acreages.\n","\n","* **Alert lag (minutes):** The distribution is strongly right-skewed, with most alerts issued within relatively short time spans, but with a long tail of cases experiencing very large delays.\n"],"metadata":{"id":"HPtwhQNN74Ng"}},{"cell_type":"markdown","source":[" **Data Standardization**\n"],"metadata":{"id":"8X0ne61uqlCD"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","Clus_dataSet = MinMaxScaler().fit_transform(df)\n","Clus_dataSet"],"metadata":{"id":"tLdjt-NtqCgr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, col in enumerate(df.columns):\n","    plt.figure(figsize=(6, 4))\n","    plt.hist(Clus_dataSet[:, i], bins=20)\n","    plt.title(f\"Histogram for standardized variable: {col}\")\n","    plt.xlabel(col)\n","    plt.ylabel(\"Frequency\")\n","    plt.grid(True)\n","    plt.show()"],"metadata":{"id":"2cHqUv1GquC4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* **Standardized acreage:** After normalization, the distribution remains strongly right-skewed, with most observations concentrated near zero and a small number of extreme fires mapped close to the upper bound, indicating persistent scale heterogeneity even after standardization.\n","\n","* **Standardized alert lag (minutes):** The standardized values are heavily concentrated near the lower end of the scale, confirming that most alerts occur relatively quickly, while a limited set of incidents exhibits disproportionately large delays.\n","\n","* **Standardized containment:** The distribution is almost entirely concentrated near one, reflecting that containment values are uniformly high across events and that standardization does not alter the underlying lack of variability in this variable.\n"],"metadata":{"id":"vb9DfrkbrXCq"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","import numpy as np # Import numpy for NaN check\n","\n","costs = []\n","K_range = range(2, 11) # Reducem la 10 pentru lizibilitate, fiind suficient pentru datele tale\n","\n","# Handle NaN values by dropping rows that contain them\n","# Convert Clus_dataSet to a pandas DataFrame to use dropna easily, then back to numpy array\n","import pandas as pd\n","Clus_dataSet_cleaned = pd.DataFrame(Clus_dataSet).dropna().values\n","\n","# Check if Clus_dataSet_cleaned is empty after dropping NaNs\n","if Clus_dataSet_cleaned.shape[0] == 0:\n","    print(\"Warning: Clus_dataSet became empty after dropping NaN values. Cannot perform KMeans.\")\n","else:\n","    for k in K_range:\n","        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","        kmeans.fit(Clus_dataSet_cleaned)\n","        costs.append(kmeans.inertia_)\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(K_range, costs, marker='o', linestyle='--', color='b')\n","    plt.xlabel('Number of Clusters (k)')\n","    plt.ylabel('Inertia (Cost)')\n","    plt.title('Elbow Method: Determining Optimal Clusters for Alert Profiling')\n","    plt.xticks(K_range)\n","    plt.grid(True, alpha=0.3)\n","    plt.show()"],"metadata":{"id":"0UXyS8xyr06P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**We will chose 3 clusters for our analysis due to sharp decrease from 2 to 3**"],"metadata":{"id":"auaBcdm6-XGG"}},{"cell_type":"code","source":["k_means = KMeans(init = \"k-means++\", n_clusters = 3, n_init = 12)\n","k_means.fit(Clus_dataSet)\n","labels_km = k_means.labels_\n","print(labels_km)"],"metadata":{"id":"Qjm6qsPlvpWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"Clus_km\"] = labels_km\n","df.head(5)"],"metadata":{"id":"phXSCLzzv3qC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Weight centers**"],"metadata":{"id":"U9Zkee2twKWS"}},{"cell_type":"code","source":["df.groupby('Clus_km').mean()"],"metadata":{"id":"HaJ2_D2IwBtq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Clus_km'].value_counts()"],"metadata":{"id":"kMVBe2LnwQjW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The cluster centers and their sizes highlight clear quantitative differences between wildfire risk profiles. **Cluster 0**, which contains the majority of observations (‚âà 384,000 events), is characterized by very high containment (‚âà 99.1%), moderate average fire size (‚âà 29,700 acres), and a mean alert lag of about **8,856 minutes**, indicating routine or controlled incidents that still experience non-negligible delays due to volume and operational load. **Cluster 1**, with roughly **121,700 events**, shows similarly high containment (‚âà 99%) but an extremely large average acreage (‚âà 429,500 acres) and the longest alert lag (‚âà 16,078 minutes), reflecting large-scale, complex mega-fires where coordination and scale drive significant delays despite stabilization. **Cluster 2**, the smallest group (‚âà 12,600 events), stands out with very low containment (‚âà 23.7%), smaller average fire size (‚âà 8,468 acres), and a high alert lag (‚âà 13,324 minutes), quantitatively confirming that low containment and active fire dynamics can lead to severe delays even when fires are not large in spatial extent.\n","\n","\n"],"metadata":{"id":"1JaMc-FoHy_t"}},{"cell_type":"code","source":["# We will make the reprezentation of clusters\n","# We will use acreage on X axis and alert_lag_min on Y axis\n","\n","ax = df[df[\"Clus_km\"] == 0][0:500].plot(\n","    kind='scatter',\n","    x='acreage',\n","    y='alert_lag_min',\n","    color='DarkBlue',\n","    label='Cluster 0: Routine/Controlled'\n",")\n","\n","df[df[\"Clus_km\"] == 1][0:500].plot(\n","    kind='scatter',\n","    x='acreage',\n","    y='alert_lag_min',\n","    color='Yellow',\n","    label='Cluster 1: Mega-Fires (Stable)',\n","    ax=ax\n",")\n","\n","df[df[\"Clus_km\"] == 2][0:500].plot(\n","    kind='scatter',\n","    x='acreage',\n","    y='alert_lag_min',\n","    color='Red',\n","    label='Cluster 2: ACTIVE RISK (23% Cont.)',\n","    ax=ax\n",")\n","\n","# We will add logarithmic scale\n","plt.xscale('log')\n","\n","plt.title('k-means results: Fire risk')\n","plt.xlabel('Surface (Acreage) - logarithmic scale')\n","plt.ylabel('Time (Minutes)')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"F02bxz9zwYdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The scatter plot shows a clear separation of wildfire incidents into three distinct risk profiles based on burned area and alert delay. Cluster 0 (blue) groups routine or controlled fires, which generally have moderate acreage and shorter alert delays, although some variability remains due to operational complexity. Cluster 1 (yellow) corresponds to mega-fires, characterized by extremely large burned areas but relatively stable and consistent alert timing, reflected by the vertical concentration at very high acreage values. Cluster 2 (red) represents active-risk fires, where lower containment and ongoing fire dynamics are associated with longer and more variable alert delays, even at moderate acreage levels.\n"],"metadata":{"id":"0et1f2y_y7il"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler # Added import\n","from sklearn.cluster import KMeans # Added import\n","\n","# Define features used for clustering and scaling, moved to top for clarity and dependency\n","features = [\"containment\", \"acreage\", \"alert_lag_min\"]\n","\n","# --- Fix Start: Define scaler and k_means to resolve NameError ---\n","# These objects were used but not defined in the current scope.\n","# We re-initialize and fit them based on the likely preceding clustering steps.\n","\n","# 1. Initialize and fit the StandardScaler on the relevant features of the DataFrame.\n","# This scales the data, which is a common preprocessing step before K-Means.\n","scaler = StandardScaler()\n","df_scaled = scaler.fit_transform(df[features])\n","\n","# 2. Initialize and fit the KMeans model.\n","# n_clusters=3 is inferred from the 'Clus_km' column values (0, 1, 2)\n","# and the plot labels/titles.\n","# random_state is added for reproducibility.\n","# n_init='auto' is a recommended setting for newer scikit-learn versions to choose\n","# the best centroids out of n_init initializations.\n","k_means = KMeans(n_clusters=3, random_state=42, n_init='auto')\n","k_means.fit(df_scaled) # Fit the model to the scaled data.\n","# --- Fix End ---\n","\n","# 4. Centers for standardized space (folosim k_means pentru k=3)\n","centers_scaled = k_means.cluster_centers_\n","\n","# 5. Centers in original values\n","centers_original = scaler.inverse_transform(centers_scaled)\n","\n","# 6. Coordinates of centers\n","idx_acreage = features.index(\"acreage\")\n","idx_lag = features.index(\"alert_lag_min\")\n","center_x = centers_original[:, idx_acreage]\n","center_y = centers_original[:, idx_lag]\n","\n","# 7. Final plot for 3 clusters\n","plt.figure(figsize=(14, 8))\n","\n","# We will use a Sample of 5000\n","df_plot = df.sample(n=5000, random_state=42).copy()\n","\n","scatter = plt.scatter(\n","    df_plot[\"acreage\"],\n","    df_plot[\"alert_lag_min\"],\n","    c=df_plot[\"Clus_km\"],\n","    cmap='viridis',\n","    alpha=0.5,\n","    s=60,\n","    edgecolors='none'\n",")\n","\n","# Add centers (red X-es)\n","plt.scatter(\n","    center_x,\n","    center_y,\n","    marker=\"X\",\n","    s=400,\n","    c=\"red\",\n","    edgecolor=\"black\",\n","    linewidth=2,\n","    label=\"Centroizi (Cluster Centers)\",\n","    zorder=10\n",")\n","\n","# Add labels\n","for i, (x, y) in enumerate(zip(center_x, center_y)):\n","    plt.text(x, y, f\"  C{i}\", fontsize=14, fontweight='bold', color='red', zorder=11)\n","\n","\n","plt.xscale('log')\n","plt.xlim(0.01, 1000000)\n","plt.ylim(-1000, 150000)\n","\n","plt.xlabel(\"Fire Size (Acreage) - Log Scale\", fontsize=12)\n","plt.ylabel(\"Alert Lag (Minutes)\", fontsize=12)\n","plt.title(\"K-means (k=3): Wildfire Risk Profiling\\n(C2 = ACTIVE RISK - 23% Containment)\", fontsize=15)\n","\n","# Legend for 3 clusters\n","handles, _ = scatter.legend_elements(prop=\"colors\", alpha=0.7)\n","# Maping numbers according to our mean\n","labels_3 = [\"C0: Routine/Controlled\", \"C1: Mega-Fires (Stable)\", \"C2: ACTIVE RISK\"]\n","plt.legend(handles, labels_3, title=\"Risk Segments\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n","\n","plt.grid(True, which=\"both\", linestyle='--', alpha=0.1)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"PvGJ5PiEy6Cz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The K-means results with three clusters reveal distinct wildfire risk profiles when fire size and alert lag are considered jointly. Cluster C0 (Routine/Controlled) groups the majority of events, spanning a wide range of fire sizes but generally associated with lower to moderate alert delays, reflecting incidents that are operationally managed despite variability in scale. Cluster C1 (Mega-Fires, Stable) is concentrated at very large acreage values, showing that extremely large fires tend to exhibit more consistent alert timing, likely due to sustained monitoring and established response protocols. Cluster C2 (Active Risk) combines very large fire sizes with relatively higher and more variable alert lags, indicating situations where low containment and ongoing fire dynamics increase operational uncertainty and delay alert escalation.\n"],"metadata":{"id":"W4kNh6VjB02I"}},{"cell_type":"code","source":["from scipy.stats import f_oneway\n","import numpy as np\n","\n","# ANOVA function for our risk variables (containment, acreage, alert_lag_min)\n","def anova_per_var(df, var_name, cluster_col=\"Clus_km\"):\n","    # Extracting values for each cluster (0, 1, 2)\n","    groups = []\n","    for c in sorted(df[cluster_col].unique()):\n","        group_data = df.loc[df[cluster_col] == c, var_name].values\n","        groups.append(group_data)\n","\n","    # F test and p value\n","    F, p = f_oneway(*groups)\n","\n","    print(f\"\\nANOVA for variable: {var_name}\")\n","    print(f\"F-statistic = {F:.3f}\")\n","    print(f\"p-value = {p:.10f}\")\n","\n","    if p < 0.05:\n","        print(f\"‚Üí Differences of {var_name} between the 3 profile risks are statistical significant (Œ± = 0.05).\")\n","    else:\n","        print(f\"‚Üí There are not any statistical differences of {var_name} between clusters.\")\n","\n","# Test\n","for col in features:\n","    anova_per_var(df, col)"],"metadata":{"id":"sxGvVkfd9_jg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Machine learning modelling**"],"metadata":{"id":"hOVJVLurCv5D"}},{"cell_type":"code","source":["# === ROUTE1 STEP 1: target (y) ===\n","T_DELAY_MIN = 60  # \"delayed alert\" (minutes)\n","\n","\n","ml_df = merged.copy()\n","\n","ml_df = ml_df[ml_df[\"alert_lag_min\"].notna()].copy()\n","ml_df = ml_df[ml_df[\"alert_lag_min\"] >= 0].copy()\n","\n","ml_df[\"delayed_alert\"] = (ml_df[\"alert_lag_min\"] > T_DELAY_MIN).astype(int)\n","\n","ml_df[\"delayed_alert\"].value_counts(dropna=False)\n"],"metadata":{"id":"JtIQ3JEAwqMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === ROUTE1 STEP 2: features (X) ===\n","\n","features = [\"acreage\", \"containment\", \"is_fps\", \"is_prescribed\"]\n","\n","features = [c for c in features if c in ml_df.columns]\n","\n","X = ml_df[features].copy()\n","y = ml_df[\"delayed_alert\"].copy()\n","\n","for c in [\"acreage\", \"containment\", \"is_fps\", \"is_prescribed\"]:\n","    if c in X.columns:\n","        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n","\n","mask = X.notna().all(axis=1) & y.notna()\n","X = X.loc[mask].copy()\n","y = y.loc[mask].copy()\n","\n","print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n","print(y.value_counts(dropna=False))\n"],"metadata":{"id":"QospOBCIwzX0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Train/Test split -- 70 to 30**"],"metadata":{"id":"VMIEOuvkDYz9"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.30,\n","    random_state=42,\n","    stratify=y\n",")\n"],"metadata":{"id":"aDPhz96jw9aP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Decision tree**"],"metadata":{"id":"6VD4TkruDl7o"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","\n","dt = DecisionTreeClassifier(max_depth=6, random_state=42)\n","dt.fit(X_train, y_train)\n"],"metadata":{"id":"WDrRn73vxC71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Random forest**"],"metadata":{"id":"MlaPnG6XyC7E"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(\n","    n_estimators=300,\n","    max_depth=10,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","rf.fit(X_train, y_train)\n"],"metadata":{"id":"hAjexHGpxRls"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**XGBoost**"],"metadata":{"id":"FCnA9VsjD8px"}},{"cell_type":"code","source":["xgb_model = None\n","try:\n","    from xgboost import XGBClassifier\n","    xgb_model = XGBClassifier(\n","        n_estimators=400,\n","        max_depth=5,\n","        learning_rate=0.05,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        random_state=42,\n","        eval_metric=\"logloss\"\n","    )\n","    xgb_model.fit(X_train, y_train)\n","    print(\"XGBoost trained.\")\n","except Exception as e:\n","    print(\"XGBoost not available / failed:\", e)\n"],"metadata":{"id":"hDd4HrKjyKM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n","\n","def eval_model(model, name):\n","    print(f\"\\n================ {name} =================\")\n","\n","    # Forecast\n","    y_pred = model.predict(X_test)\n","    cm = confusion_matrix(y_test, y_pred)\n","\n","    # Confusion Matrix\n","    fig, ax = plt.subplots(figsize=(5, 4))\n","    sns.heatmap(\n","        cm,\n","        annot=True,\n","        fmt=\"d\",\n","        cmap=\"Blues\",\n","        cbar=False,\n","        ax=ax\n","    )\n","    ax.set_title(f\"Confusion Matrix ‚Äì {name}\")\n","    ax.set_xlabel(\"Predicted label\")\n","    ax.set_ylabel(\"True label\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # === Statistics ===\n","    print(\"Classification report:\")\n","    print(classification_report(y_test, y_pred, digits=4))\n","\n","    # ===  ROC AUC  ===\n","    if hasattr(model, \"predict_proba\"):\n","        y_prob = model.predict_proba(X_test)[:, 1]\n","        auc = roc_auc_score(y_test, y_prob)\n","        print(f\"ROC AUC: {auc:.4f}\")\n","    else:\n","        print(\"ROC AUC: not available (no predict_proba)\")\n"],"metadata":{"id":"gkWndSVoypbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_model(dt, \"Decision Tree\")\n","eval_model(rf, \"Random Forest\")\n","eval_model(xgb_model, \"XGBoost\")\n"],"metadata":{"id":"XEVqSuh6zakq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Decision Tree**\n","\n","The confusion matrix shows that the model correctly identifies 130,283 delayed alerts (true positives) while missing 601 delayed cases (false negatives), resulting in a very high recall for the delayed class of 0.9954. However, performance on the non-delayed class is weak: only 874 non-delayed alerts are correctly classified, while 9,613 are incorrectly flagged as delayed, which explains the very low recall of 0.0833 for class 0. The overall accuracy is 0.9278, but this is driven mainly by the dominance of the delayed class. The ROC AUC of 0.8355 indicates limited discrimination ability, reflecting the model‚Äôs difficulty in separating non-delayed alerts from delayed ones.\n","\n","**Random Forest**\n","\n","The confusion matrix indicates 130,178 true positives and 706 false negatives, leading to a delayed-alert recall of 0.9946, meaning that almost all delayed alerts are detected. For the non-delayed class, the model correctly classifies 1,000 cases, but still misclassifies 9,487 non-delayed alerts as delayed, yielding a recall of 0.0954 for class 0. The overall accuracy is 0.9279, similar to the Decision Tree, but with slightly better identification of non-delayed cases. The ROC AUC of 0.8474 reflects improved class separation compared to the Decision Tree, although misclassification of non-delayed alerts remains substantial.\n","\n","**XGBoost**\n","\n","The confusion matrix shows 130,249 true positives and 635 false negatives, resulting in a delayed-alert recall of 0.9951, which means delayed alerts are almost never missed. For non-delayed alerts, 860 cases are correctly identified, while 9,627 are incorrectly labeled as delayed, corresponding to a recall of 0.0820 for class 0. The overall accuracy reaches 0.9274, again driven by strong performance on the delayed class. The ROC AUC value of 0.8465 indicates strong discrimination ability, slightly below Random Forest in this run, but still clearly higher than the Decision Tree."],"metadata":{"id":"td_rjkWxFOUc"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, roc_curve\n",")\n","\n","def get_model_scores(model, X):\n","\n","    if hasattr(model, \"predict_proba\"):\n","        return model.predict_proba(X)[:, 1]\n","    if hasattr(model, \"decision_function\"):\n","        return model.decision_function(X)\n","    return None\n","\n","def evaluate_models(models_dict, X_test, y_test):\n","    rows = []\n","    roc_data = {}\n","\n","    for name, model in models_dict.items():\n","        y_pred = model.predict(X_test)\n","        scores = get_model_scores(model, X_test)\n","\n","        # classic metrics\n","        acc = accuracy_score(y_test, y_pred)\n","        prec = precision_score(y_test, y_pred, zero_division=0)\n","        rec = recall_score(y_test, y_pred, zero_division=0)\n","        f1 = f1_score(y_test, y_pred, zero_division=0)\n","\n","        # ROC AUC + ROC curve\n","        auc = np.nan\n","        fpr = tpr = thr = None\n","        if scores is not None:\n","            auc = roc_auc_score(y_test, scores)\n","            fpr, tpr, thr = roc_curve(y_test, scores)\n","            roc_data[name] = (fpr, tpr, auc)\n","\n","        rows.append({\n","            \"Model\": name,\n","            \"Accuracy\": acc,\n","            \"Precision\": prec,\n","            \"Recall\": rec,\n","            \"F1\": f1,\n","            \"ROC_AUC\": auc\n","        })\n","\n","    results_df = pd.DataFrame(rows).sort_values(by=\"ROC_AUC\", ascending=False)\n","    return results_df, roc_data\n","\n","# === MODELS ===\n","models = {\n","    \"Decision Tree\": dt,\n","    \"Random Forest\": rf\n","}\n","if xgb_model is not None:\n","    models[\"XGBoost\"] = xgb_model\n","\n","results_df, roc_data = evaluate_models(models, X_test, y_test)\n","\n","print(\"=== Model Comparison Table ===\")\n","display(results_df.style.format({\n","    \"Accuracy\": \"{:.4f}\",\n","    \"Precision\": \"{:.4f}\",\n","    \"Recall\": \"{:.4f}\",\n","    \"F1\": \"{:.4f}\",\n","    \"ROC_AUC\": \"{:.4f}\"\n","}))\n","\n","# === ROC CURVES===\n","plt.figure(figsize=(8, 6))\n","for name, (fpr, tpr, auc) in roc_data.items():\n","    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n","\n","#random line\n","plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random (AUC=0.5)\")\n","\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curves ‚Äì Model Comparison\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"iPvFYaEI1JTy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The results indicate that all three models perform at a consistently high level, with accuracy values of approximately 92.7‚Äì92.8%, which shows that the available information captures well the factors associated with alert delays. This suggests that the problem is well defined and that the selected features contain meaningful signals for distinguishing between delayed and non-delayed alerts.\n","\n","Among the evaluated models, Random Forest achieves the highest ROC AUC value (‚âà 0.847), followed very closely by XGBoost (‚âà 0.846), while the Decision Tree records a lower value (‚âà 0.836). Although the differences between Random Forest and XGBoost are small, the ROC AUC values indicate that the ensemble-based models provide superior discrimination between delayed and non-delayed alerts across different decision thresholds.\n","\n","The ROC curves further confirm this result, as the Random Forest and XGBoost curves consistently lie above the Decision Tree curve for most values of the false positive rate. This indicates that, for the same proportion of false alarms, these models are able to correctly identify a larger share of delayed alerts. In practical terms, both ensemble models provide more reliable probabilistic signals that can be adjusted to different operational thresholds, without a disproportionate increase in unnecessary alerts.\n","\n","XGBoost and Random Forest both demonstrate strong and stable performance, while the single Decision Tree, although slightly weaker in terms of discrimination power, still performs well and offers greater interpretability. Overall, the results support the use of an ensemble-based approach for the alerting system, as these models offer the best balance between predictive accuracy and risk discrimination, which is essential for supporting timely and effective alert decisions.\n"],"metadata":{"id":"ZcZjCR0Q1qCu"}},{"cell_type":"code","source":["best_model_name = results_df.iloc[0][\"Model\"]\n","final_model = models[best_model_name]\n","\n","print(\"Final model selected:\", best_model_name)\n"],"metadata":{"id":"aKlR-Yd52S0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def alert_policy(p_delay: float) -> str:\n","    if p_delay >= 0.70:\n","        return \"HIGH\"\n","    elif p_delay >= 0.40:\n","        return \"MEDIUM\"\n","    else:\n","        return \"LOW\"\n"],"metadata":{"id":"vHAaYCa12grj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PLAYBOOK = {\n","    \"LOW\": {\n","        \"EN\": \"Low risk. Monitor official updates and keep notifications enabled.\",\n","        \"RO\": \"Risc redus. UrmƒÉri»õi actualizƒÉrile oficiale »ôi pƒÉstra»õi notificƒÉrile active.\",\n","        \"ES\": \"Riesgo bajo. Siga las actualizaciones oficiales y mantenga las notificaciones activas.\"\n","    },\n","    \"MEDIUM\": {\n","        \"EN\": \"Medium risk. Prepare for evacuation. Stay alert and review local guidance.\",\n","        \"RO\": \"Risc mediu. PregƒÉti»õi-vƒÉ pentru evacuare. RƒÉm√¢ne»õi √Æn alertƒÉ »ôi urma»õi indica»õiile locale.\",\n","        \"ES\": \"Riesgo medio. Prep√°rese para evacuar. Mant√©ngase alerta y siga las indicaciones locales.\"\n","    },\n","    \"HIGH\": {\n","        \"EN\": \"High risk. If evacuation is ordered, leave immediately. Follow official instructions.\",\n","        \"RO\": \"Risc ridicat. DacƒÉ existƒÉ ordin de evacuare, pleca»õi imediat. Urma»õi instruc»õiunile oficiale.\",\n","        \"ES\": \"Riesgo alto. Si hay orden de evacuaci√≥n, salga inmediatamente. Siga las instrucciones oficiales.\"\n","    }\n","}\n","\n","def build_alert(p_delay: float, lang=\"RO\"):\n","    level = alert_policy(p_delay)\n","    msg = PLAYBOOK[level].get(lang, PLAYBOOK[level][\"EN\"])\n","    return level, msg\n"],"metadata":{"id":"-QLw6FoB22uX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_delay_prob(model, X_row):\n","    if hasattr(model, \"predict_proba\"):\n","        return float(model.predict_proba(X_row)[:, 1][0])\n","    if hasattr(model, \"decision_function\"):\n","        score = float(model.decision_function(X_row)[0])\n","        return 1 / (1 + np.exp(-score))\n","    raise ValueError(\"Model has no probability or decision function.\")\n","\n","# Sample on records of X_test\n","demo_idx = X_test.sample(n=min(100, len(X_test)), random_state=42).index\n","demo_X = X.loc[demo_idx]\n","\n","cols_show = [c for c in [\"name\", \"acreage\", \"containment\", \"rate_of_spread\", \"structure_threat\", \"spotting\", \"alert_lag_min\"] if c in ml_df.columns]\n","demo_info = ml_df.loc[demo_idx, cols_show].copy()\n","\n","probs = []\n","levels = []\n","msg_ro = []\n","msg_en = []\n","msg_es = []\n","for i in range(demo_X.shape[0]):\n","    p = predict_delay_prob(final_model, demo_X.iloc[[i]])\n","    lv, mro = build_alert(p, \"RO\")\n","    _, men = build_alert(p, \"EN\")\n","    _, mes = build_alert(p, \"ES\")\n","    probs.append(p); levels.append(lv); msg_ro.append(mro); msg_en.append(men) ; msg_es.append(mes)\n","\n","demo_info[\"p_delayed\"] = probs\n","demo_info[\"alert_level\"] = levels\n","demo_info[\"message_RO\"] = msg_ro\n","demo_info[\"message_EN\"] = msg_en\n","demo_info[\"message_ES\"] = msg_es\n","\n","demo_info.sort_values(\"p_delayed\", ascending=False)"],"metadata":{"id":"nSRmieW827AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What each cluster looks like\n","display(df.groupby(\"Clus_km\")[[\"containment\", \"acreage\", \"alert_lag_min\"]].mean())\n","\n","T_DELAY_MIN = 60\n","df_tmp = df.copy()\n","df_tmp[\"delayed_alert\"] = (df_tmp[\"alert_lag_min\"] > T_DELAY_MIN).astype(int)\n","\n","cluster_delay = df_tmp.groupby(\"Clus_km\")[\"delayed_alert\"].mean().rename(\"delayed_rate\")\n","display(cluster_delay.to_frame())\n"],"metadata":{"id":"9-yqUZng3Pd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import folium\n","from IPython.display import display, HTML\n","\n","# Checking required columns\n","required_cols = {\"lat\", \"lng\", \"alert_lag_min\"}\n","if not required_cols.issubset(merged.columns):\n","    print(\"Missing required columns:\", required_cols - set(merged.columns))\n","else:\n","    # Sample for performance\n","    geo_delay = (\n","        merged\n","        .dropna(subset=[\"lat\", \"lng\", \"alert_lag_min\"])\n","        .sample(n=min(2000, len(merged)), random_state=42)\n","        .copy()\n","    )\n","\n","    geo_delay[\"Lag (min)\"] = geo_delay[\"alert_lag_min\"].round(1)\n","\n","    # Popup\n","    geo_delay[\"Popup\"] = (\n","        \"<b>\" + geo_delay[\"name\"].astype(str) + \"</b><br>\"\n","        \"Alert lag: \" + geo_delay[\"Lag (min)\"].astype(str) + \" min<br>\"\n","        \"Containment: \" + geo_delay[\"containment\"].astype(str) + \"%<br>\"\n","        \"Acreage: \" + geo_delay[\"acreage\"].astype(str)\n","    )\n","\n","    # Map\n","    m = folium.Map(\n","        location=[geo_delay[\"lat\"].mean(), geo_delay[\"lng\"].mean()],\n","        zoom_start=6,\n","        tiles=\"CartoDB positron\"\n","    )\n","\n","    # Markers according to ML thresholds\n","    for _, row in geo_delay.iterrows():\n","        lag = row[\"alert_lag_min\"]\n","\n","        if lag <= 60:\n","            color = \"#4CAF50\"      # green - OK\n","        elif lag <= 1440:\n","            color = \"#F4A261\"      # orange - delayed\n","        else:\n","            color = \"#9B2226\"      # dark red - severe delay\n","\n","        folium.CircleMarker(\n","            location=[row[\"lat\"], row[\"lng\"]],\n","            radius=4,\n","            color=color,\n","            fill=True,\n","            fill_opacity=0.7,\n","            popup=folium.Popup(row[\"Popup\"], max_width=300)\n","        ).add_to(m)\n","\n","    # Legend\n","    legend_html = \"\"\"\n","     <div style=\"\n","         position: fixed;\n","         bottom: 50px; left: 50px;\n","         width: 220px; height: 130px;\n","         background-color: white;\n","         border:2px solid grey;\n","         z-index:9999;\n","         font-size:14px;\n","         box-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n","         padding: 8px;\n","     \">\n","         <b>Alert Lag (minutes)</b><br>\n","         <span style=\"color:#4CAF50;\">‚óè</span> &nbsp; ‚â§ 60 min (OK)<br>\n","         <span style=\"color:#F4A261;\">‚óè</span> &nbsp; 60‚Äì1440 min (Delayed)<br>\n","         <span style=\"color:#9B2226;\">‚óè</span> &nbsp; &gt; 1440 min (Severe delay)\n","     </div>\n","    \"\"\"\n","\n","    m.get_root().html.add_child(folium.Element(legend_html))\n","\n","    # Save + display\n","    m.save(\"delay_map_ml_thresholds.html\")\n","    display(HTML(m._repr_html_()))\n","\n","    print(\"Map saved as: delay_map_ml_thresholds.html\")\n","\n"],"metadata":{"id":"KkY4gWGe6z6q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Results**"],"metadata":{"id":"gLHPXyhH5AeO"}},{"cell_type":"markdown","source":["**Model Performance Metrics**\n","\n","The supervised learning models demonstrate strong and consistent predictive performance in identifying delayed wildfire alerts. All evaluated models achieve an overall accuracy of approximately 92.7‚Äì92.8%, confirming that alert delays can be reliably predicted using the selected operational features. This indicates that the problem formulation is appropriate and that the chosen variables capture meaningful signals related to alert delays.\n","\n","Among the evaluated models, Random Forest and XGBoost exhibit the strongest overall performance, with very similar results across all metrics. Both models achieve high precision (‚âà 0.93) and exceptionally high recall (above 99%) for delayed alerts, indicating that nearly all truly delayed cases are correctly identified. This property is essential in an alerting context, where failing to detect delayed alerts represents the most costly type of error. In terms of discrimination power, Random Forest attains the highest ROC AUC (‚âà 0.847), closely followed by XGBoost (‚âà 0.846), while the Decision Tree records a lower value (‚âà 0.836). Although the numerical differences are modest, they are consistent across ROC curves and evaluation metrics, highlighting the advantage of ensemble-based methods over a single-tree model.\n","\n","**Clustering-Based Risk Profiling**\n","\n","The unsupervised clustering analysis identifies three statistically distinct wildfire risk profiles, each characterized by clearly different numerical patterns. One cluster corresponds to very large-scale incidents with near-total containment (‚âà 99%) but the longest alert delays (over 16,000 minutes) and the highest delayed alert rate (above 98%), highlighting the operational complexity associated with mega-fires. A second cluster also exhibits high containment (‚âà 99.1%) but significantly smaller average fire size (‚âà 29,700 acres) and shorter alert delays (‚âà 8,856 minutes), indicating faster alert handling when incident scale is reduced. The third cluster is defined by very low containment (‚âà 23.7%), moderate fire size (‚âà 8,468 acres), and long alert delays (over 13,300 minutes), demonstrating that low containment alone can drive substantial alert delays, independently of fire scale.\n","\n","**Key Findings and Visual Insights**\n","\n","Visualizations support and reinforce these findings. Histograms reveal highly skewed distributions for acreage and alert lag, justifying normalization prior to clustering. The elbow method clearly indicates three clusters as the optimal choice, balancing interpretability and explanatory power. Scatter plots in logarithmic scale show clear separation between routine, mega-fire, and active-risk profiles, while confusion matrices and ROC curves illustrate the strong predictive capability of the supervised models, particularly the ensemble approaches. Spatial visualizations further contextualize alert delays geographically, linking model outputs to real-world locations.\n","\n","**Model Selection and Operational Implications**\n","\n","Based on quantitative performance metrics and visual diagnostics, an ensemble-based model is selected for the alerting framework, with Random Forest and XGBoost both representing suitable choices due to their strong discrimination power and extremely high recall for delayed alerts. When combined with predefined probability thresholds, their outputs can be translated into actionable alert levels that distinguish low-risk situations from those requiring early escalation. The alignment between clustering-derived risk profiles and supervised predictions further validates the framework, as higher delay probabilities are consistently assigned to incidents characterized by extreme acreage or low containment.\n","\n","**Limitations and Ethical Considerations**\n","\n","Several limitations should be acknowledged. The analysis relies on historical incident data and does not incorporate real-time sensor inputs or physical fire-spread modeling. Population exposure and individual-level vulnerability are not directly modeled, and the system is designed to support decision-making rather than automate evacuation orders. From an ethical perspective, the framework prioritizes transparency and interpretability, ensuring that alert decisions can be audited and explained, while minimizing the risk of systematically missing high-risk delayed alerts."],"metadata":{"id":"b8j55x3-5JZ9"}},{"cell_type":"markdown","source":["## Team Contributions\n","\n","| Name         | Contributions                                |\n","|--------------|----------------------------------------------|\n","| »öilicƒÉ Mihnea David       | EDA, Model Validation          |\n","| Radu Alexandru Claudiu           | \tEDA, Model Testing      |\n","| Zamfir Robert Dan     | Clustering, Model Training            |\n","| Sasu Sabrina          |Clustering, Model Validation         |\n","| SƒÉndulescu Crina     | Model Testing, Data Cleaning            |\n","| Sandu Bianca Antonia  | Model Training, Data Cleaning       |"],"metadata":{"id":"m1f1MhXsY6RW"}}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/sasusabrina22/wids-datathon-template/blob/main/notebook.ipynb","timestamp":1766513202458}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8"}},"nbformat":4,"nbformat_minor":0}